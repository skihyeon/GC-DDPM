import gradio as gr
import os
from generate import HandwritingGenerator
from config import InferenceConfig
from PIL import Image
import numpy as np
from typing import List

class HandwritingService:
    def __init__(self):
        """ì†ê¸€ì”¨ ìƒì„± ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.config = InferenceConfig()
        self.generator = HandwritingGenerator(
            checkpoint_path=os.path.join(self.config.checkpoint_dir, self.config.checkpoint_name),
            config=self.config
        )
    
    def generate_handwriting(
        self, 
        text: str,
        writer_id: int,
        content_scale: float = 3.0,
        style_scale: float = 1.0,
        num_inference_steps: int = 5,
    ) -> tuple[np.ndarray]:
        """ì†ê¸€ì”¨ ì´ë¯¸ì§€ ìƒì„±"""
        if not text.strip():
            raise gr.Error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
        # writer_idê°€ -1ì´ë©´ ëœë¤ ì„ íƒ
        writer_id = None if writer_id == -1 else writer_id
            
        # ì´ë¯¸ì§€ ìƒì„±
        images = self.generator.generate(
            text=text,
            writer_id=writer_id,
            num_samples=self.config.num_samples,
            content_scale=content_scale,
            style_scale=style_scale,
            num_inference_steps=num_inference_steps
        )
        
        # PIL ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì§•í•˜ê³  numpy ë°°ì—´ë¡œ ë³€í™˜
        result = []
        for img in images:
            # ë†’ì´ë¥¼ 64ë¡œ ê³ ì •í•˜ê³  ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì§•
            w = int(img.size[0] * (64 / img.size[1]))
            resized_img = img.resize((w, 64), Image.Resampling.LANCZOS)
            
            # 512 í¬ê¸°ì˜ ê²€ì€ìƒ‰ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
            final_img = Image.new('L', (512, 64), 255)
            # ì¤‘ì•™ì— ë¦¬ì‚¬ì´ì§•ëœ ì´ë¯¸ì§€ ë¶™ì´ê¸°
            x = (512 - w) // 2
            final_img.paste(resized_img, (x, 0))
            
            result.append(np.array(final_img))
            
        # ë¶€ì¡±í•œ ìƒ˜í”Œ ìˆ˜ë§Œí¼ None ì¶”ê°€
        result = result + [None] * (self.config.num_samples - len(result))
        return tuple(result)

def create_demo() -> gr.Interface:
    service = HandwritingService()
    
    def generate(
        text: str,
        writer_id: int,
        content_scale: float,
        style_scale: float,
        num_inference_steps: int,
    ) -> tuple[np.ndarray]:
        return service.generate_handwriting(
            text=text,
            writer_id=writer_id,
            content_scale=content_scale,
            style_scale=style_scale,
            num_inference_steps=num_inference_steps
        )
    
    # ì˜ˆì œ ë°ì´í„° ì •ì˜
    examples = [
        ["ì•ˆë…•í•˜ì„¸ìš”", -1, 3.0, 1.0, 20],
        ["í…ŒìŠ¤íŠ¸", -1, 3.0, 1.0, 20],
        ["ì†ê¸€ì”¨", -1, 3.0, 1.0, 20],
        ["Hello!", -1, 3.0, 1.0, 20],
        ["Test", -1, 3.0, 1.0, 20],
        ["Handwriting", -1, 3.0, 1.0, 20]
    ]
    
    with gr.Blocks() as demo:
        gr.Markdown("# ğŸ–‹ï¸ AI ì†ê¸€ì”¨ ìƒì„±ê¸°")
        gr.Markdown("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        
        with gr.Row():
            with gr.Column(scale=1):
                text_input = gr.Textbox(
                    label="í…ìŠ¤íŠ¸",
                    placeholder="ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                    lines=2
                )
                writer_id = gr.Dropdown(
                    choices=[("ëœë¤", -1)] + [(f"ì‘ì„±ì {i}", i) for i in range(service.config.num_writers)],
                    value=-1,
                    label="ì‘ì„±ì ì„ íƒ"
                )
                content_scale = gr.Slider(
                    label="ì»¨í…ì¸  ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                    minimum=0.0,
                    maximum=4.0,
                    step=0.1,
                    value=3.0,
                    info="ë†’ì„ìˆ˜ë¡ ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ë” ì¼ì¹˜í•˜ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ë§Œ, ë‹¤ì–‘ì„±ì´ ì¤„ì–´ë“­ë‹ˆë‹¤."
                )
                style_scale = gr.Slider(
                    label="ìŠ¤íƒ€ì¼ ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                    minimum=0.0,
                    maximum=1.0,
                    step=0.1,
                    value=1.0,
                    info="ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì‘ì„±ìì˜ ìŠ¤íƒ€ì¼ì„ ì–¼ë§ˆë‚˜ ë”°ë¥¼ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
                )
                num_inference_steps = gr.Slider(
                    label="ì¶”ë¡  ìŠ¤í… ìˆ˜",
                    minimum=1,
                    maximum=100,
                    step=1,
                    value=10
                )
                generate_btn = gr.Button("ìƒì„±í•˜ê¸°")
            
            with gr.Column(scale=2):
                output_images = [
                    gr.Image(label=f"ìƒ˜í”Œ {i+1}", show_label=True, type="numpy")
                    for i in range(service.config.num_samples)
                ]
        
        # Examples ì»´í¬ë„ŒíŠ¸ ìˆ˜ì •
        gr.Examples(
            examples=examples,
            inputs=[
                text_input,
                writer_id,
                content_scale,
                style_scale,
                num_inference_steps
            ],
            outputs=output_images,
            fn=generate,
            cache_examples=True,  # ìºì‹œ ë¹„í™œì„±í™”
            label="ì˜ˆì œ",  # ì˜ˆì œ ì„¹ì…˜ ë ˆì´ë¸” ì¶”ê°€,
            run_on_click=True
        )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        generate_btn.click(
            fn=generate,
            inputs=[text_input, writer_id, content_scale, style_scale, num_inference_steps],
            outputs=output_images,

        )
    
    return demo

def main():
    demo = create_demo()
    config = InferenceConfig()
    demo.launch(
        server_name=config.server_name,
        server_port=config.server_port,
        share=config.share,
    )

if __name__ == "__main__":
    main() 